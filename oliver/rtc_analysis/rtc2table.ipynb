{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main notebook task\n",
    "# Read RTC and create a 3 by 3 data collection. \n",
    "# Store into a csv and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import ast\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from val_io import get_burst_time_series_around_point\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert string\n",
    "def convert_to_list(v):\n",
    "    if isinstance(v, str):\n",
    "        return ast.literal_eval(v)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load necessary tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sites\n",
    "df_sites = gpd.read_file('https://github.com/taliboliver/dist-s1-validation-harness/blob/dev/data/val_sites_subset.geojson?raw=true')\n",
    "\n",
    "# Read busts\n",
    "df_val_bursts = gpd.read_parquet('./validation_bursts_v1_coverage_updated.parquet')\n",
    "\n",
    "# Get a list of site ID's\n",
    "unique_site_ids = df_sites['site_id'].unique().tolist()\n",
    "print(len(unique_site_ids))\n",
    "print(unique_site_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run for all sites\n",
    "- The cell below will iterate over all sites and their respective overlapping bursts. \n",
    "- It will generate a csv table using a 3x3 window centered at the particular site latitude and longitude.\n",
    "- The script will read the output csv and create a png plot.\n",
    "- The outputs are directed to the /tables and /plots directories inside the predifined out_dir. Please ensure this two directories exist.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define run parameters \n",
    "out_dir = '/Users/cabrera/Documents/jpl_projects/opera_dist/dist-s1-research/oliver/rtc_analysis'\n",
    "create_plot = 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over sites\n",
    "for SITE_ID in unique_site_ids:\n",
    "    # Read site\n",
    "    df_site = df_sites[df_sites.site_id == SITE_ID].reset_index(drop=True)\n",
    "\n",
    "    # Load site geometry\n",
    "    geo = df_site.geometry[0]\n",
    "    lon, lat = geo.x, geo.y\n",
    "\n",
    "    # For a selected site find corresponding bursts\n",
    "    df_bursts_for_site = df_val_bursts[df_val_bursts.jpl_burst_id.isin(df_site.jpl_burst_id)].reset_index(drop=True)\n",
    "\n",
    "    # Loop over bursts and read data\n",
    "    for IDX_BURST in range(len(df_bursts_for_site)):\n",
    "        # Get RTC data per burst\n",
    "        BURST_ID = df_bursts_for_site.iloc[IDX_BURST].jpl_burst_id\n",
    "\n",
    "        # check if the table exists already \n",
    "        out_csv = f'{out_dir}/tables/rtc_summary_site_{SITE_ID}_burst_{BURST_ID}.csv'\n",
    "        if os.path.exists(out_csv):\n",
    "            print(f\"File '{out_csv}' exists! Skipping...\")\n",
    "            continue\n",
    "\n",
    "        df_rtc = pd.read_json('data/rtc_s1_table.json.zip')\n",
    "        df_rtc_ts = df_rtc[df_rtc.jpl_burst_id == BURST_ID].reset_index(drop=True)\n",
    "        df_rtc_ts['acq_datetime'] = pd.to_datetime(df_rtc_ts['acq_datetime'])\n",
    "\n",
    "        # Load arrays\n",
    "        vv_arrs = get_burst_time_series_around_point(df_rtc_ts.rtc_s1_vv_url.tolist(), lon, lat, window_size=3)\n",
    "        vh_arrs = get_burst_time_series_around_point(df_rtc_ts.rtc_s1_vh_url.tolist(), lon, lat)\n",
    "\n",
    "        # Generate the geodatarframe for the corresponding data\n",
    "        vv_flattened = []\n",
    "        vh_flattened = []\n",
    "        vv_vh_flattened = []\n",
    "        dates = df_rtc_ts['acq_datetime']\n",
    "\n",
    "        # Loop over the arrays and dates\n",
    "        for vv_array, vh_array, date in zip(vv_arrs, vh_arrs, dates):\n",
    "            vv_flat = vv_array.flatten().tolist()\n",
    "            vh_flat = vh_array.flatten().tolist()\n",
    "            \n",
    "            # Compute vv/vh with handling division by zero\n",
    "            with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                ratio = np.divide(vv_array, vh_array)\n",
    "                ratio[np.isnan(ratio) | np.isinf(ratio)] = -9999\n",
    "            ratio_flat = ratio.flatten().tolist()\n",
    "\n",
    "            vv_flattened.append(vv_flat)\n",
    "            vh_flattened.append(vh_flat)\n",
    "            vv_vh_flattened.append(ratio_flat)\n",
    "\n",
    "        # Create a DataFrame with the flattened lists and dates\n",
    "        data = {\n",
    "            'datetime': dates,\n",
    "            'vv': vv_flattened,\n",
    "            'vh': vh_flattened,\n",
    "            'vv/vh': vv_vh_flattened\n",
    "        }\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        df['burst_id'] = BURST_ID\n",
    "        df['site_id'] = SITE_ID\n",
    "        df['site_lon'] = lon\n",
    "        df['site_lat'] = lat\n",
    "\n",
    "        desired_order = ['datetime', 'burst_id', 'site_id', 'site_lon', 'site_lat', 'vv', 'vh', 'vv/vh']\n",
    "        df = df[desired_order]\n",
    "\n",
    "        # Export table\n",
    "        df.to_csv(out_csv)\n",
    "\n",
    "        if create_plot == 'yes':\n",
    "            # load csv and plot\n",
    "            burst_df = pd.read_csv(out_csv)\n",
    "            # convert lists\n",
    "            burst_df['vv'] = burst_df['vv'].apply(convert_to_list)\n",
    "            burst_df['vh'] = burst_df['vh'].apply(convert_to_list)\n",
    "            burst_df['vv/vh'] = burst_df['vv/vh'].apply(convert_to_list)\n",
    "\n",
    "            # Calculate the average of each list in the column vv and add ne average column\n",
    "            burst_df['vv_avg'] = burst_df['vv'].apply(lambda x: sum(x) / len(x) if isinstance(x, list) else x)\n",
    "            burst_df['vh_avg'] = burst_df['vh'].apply(lambda x: sum(x) / len(x) if isinstance(x, list) else x)\n",
    "            burst_df['vv/vh_avg'] = burst_df['vv/vh'].apply(lambda x: sum(x) / len(x) if isinstance(x, list) else x)\n",
    "\n",
    "            # convert datetime\n",
    "            burst_df['datetime'] = pd.to_datetime(burst_df['datetime'])\n",
    "\n",
    "            # plot data\n",
    "            fig, ax1 = plt.subplots(figsize=(20, 5))\n",
    "            ax1.plot(burst_df['datetime'], burst_df['vv_avg'], marker='o', color='tab:blue', label='vv_avg')\n",
    "            ax1.set_xlabel('Datetime')\n",
    "            ax1.set_ylabel('vv_avg', color='tab:blue')\n",
    "            ax1.tick_params(axis='y', labelcolor='tab:blue')\n",
    "            ax2 = ax1.twinx()\n",
    "            ax2.plot(burst_df['datetime'], burst_df['vh_avg'], marker='v', color='tab:brown', label='vh_avg')\n",
    "            ax2.set_ylabel('vh_avg', color='tab:brown')\n",
    "            ax2.tick_params(axis='y', labelcolor='tab:brown')\n",
    "            ax3 = ax1.twinx()\n",
    "            ax3.spines['right'].set_position(('outward', 60))  \n",
    "            ax3.plot(burst_df['datetime'], burst_df['vv/vh_avg'], marker='P', color='tab:purple', label='vv/vh_avg')\n",
    "            ax3.set_ylabel('vv/vh_avg', color='tab:purple')\n",
    "            ax3.tick_params(axis='y', labelcolor='tab:purple')\n",
    "\n",
    "            change_type = df_site.change_type.iloc[0]\n",
    "            plt.title(f'Change type {change_type}; {BURST_ID=}; {SITE_ID=}')\n",
    "\n",
    "            ax1.set_xticks(df_rtc_ts['acq_datetime'].tolist())\n",
    "            ax1.set_xticklabels(burst_df['datetime'], rotation=90)\n",
    "\n",
    "            ax1.grid(True)\n",
    "\n",
    "            last_observed_time = df_site['last_observation_time'][0]\n",
    "\n",
    "            if not isinstance(last_observed_time, type(pd.NaT)):\n",
    "                ax1.axvline(x=last_observed_time, color='b', linestyle='--', label=f'Last observation time ({last_observed_time})')\n",
    "            ax2.legend(loc='upper left')\n",
    "\n",
    "            change_time = df_site['change_time'][0]\n",
    "            if not isinstance(change_time, type(pd.NaT)):\n",
    "                ax1.axvline(x=change_time, color='r', linestyle='--', label=f'Change time ({change_time})')\n",
    "            ax1.legend()\n",
    "\n",
    "            fig.tight_layout()\n",
    "\n",
    "            # save plot\n",
    "            plt.savefig(f'{out_dir}/plots/rtc_summary_site_{SITE_ID}_burst_{BURST_ID}.png', bbox_inches='tight', transparent=False, dpi=150)\n",
    "            plt.close()\n",
    "            print(f\"Saved figure burst_{BURST_ID}_site_{SITE_ID}_rtc_ts.png\")\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dist-s1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
